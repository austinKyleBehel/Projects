{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "pygame 1.9.6\nHello from the pygame community. https://www.pygame.org/contribute.html\nParticipant: 12012\n"
    }
   ],
   "source": [
    "''' Setup '''\n",
    "import os, sys,time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from psychopy import prefs\n",
    "prefs.hardware['audioLib'] = ['PTB']\n",
    "from psychopy import sound\n",
    "from psychopy import visual, monitors, gui, event, core, logging\n",
    "import psychtoolbox as ptb \n",
    "\n",
    "\n",
    "from string import ascii_letters, digits\n",
    "import numpy.matlib\n",
    "import random\n",
    "import math \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set to 1 if True\n",
    "islaptop = 0\n",
    "isfullscreen = 1\n",
    "iseyetracking = 0\n",
    "refreshrate = 60\n",
    "\n",
    "if iseyetracking:\n",
    "    import pylink\n",
    "    from EyeLinkCoreGraphicsPsychoPy import EyeLinkCoreGraphicsPsychoPy\n",
    "\n",
    "# Set up a  data folder to save the results\n",
    "results_folder = 'data_temporal_estimation'\n",
    "if not os.path.exists(results_folder):\n",
    "    os.makedirs(results_folder)\n",
    "\n",
    "# Prompt user to specify a filename\n",
    "dlg_title = 'Enter Participant'\n",
    "dlg_prompt = 'Please enter participant number'\n",
    "fname = 'TEST'\n",
    "while True:\n",
    "    dlg = gui.Dlg(dlg_title)\n",
    "    dlg.addText(dlg_prompt)\n",
    "    dlg.addField('Participant Number:', fname)\n",
    "    # show dialog and wait for OK or Cancel\n",
    "    ok_data = dlg.show()\n",
    "    if dlg.OK:  # if ok_data is not None\n",
    "        print('Participant: {}'.format(ok_data[0]))\n",
    "    else:\n",
    "        print('user cancelled')\n",
    "        core.quit()\n",
    "\n",
    "    # get the string entered\n",
    "    fname = 'P' + dlg.data[0]\n",
    "    assert not os.path.exists('./' + results_folder +'/' + fname + '_trialmat.csv'), \"FILE ALREADY EXISTS\"\n",
    "\n",
    "    # check if the filename is valid for eye tracking (length <= 8 & no special char)\n",
    "    allowed_char = ascii_letters + digits + '_'\n",
    "    if not all([c in allowed_char for c in fname]):\n",
    "        print('ERROR: Invalid EDF filename')\n",
    "    elif len(fname) > 8:\n",
    "        print('ERROR: EDF filename should not exceed 8 characters')\n",
    "    else:\n",
    "        break\n",
    "# fname = 'TEST_s'\n",
    "\n",
    "def screeninfo(islaptop):\n",
    "    if islaptop==1:\n",
    "        monitorwidth = 33. # monitor width in cm\n",
    "        viewdist = 50\n",
    "    else:\n",
    "        monitorwidth = 53.5 # monitor width in cm (64 for eyetracking pc, 60 for my desktop)\n",
    "        viewdist = 57\n",
    "    return {'viewdist':viewdist,'monitorwidth':monitorwidth}\n",
    "\n",
    "def deg_to_pix(dva,screen_info,scn_width):\n",
    "    size_cm = screen_info['viewdist']*np.tan(np.deg2rad(dva/2))*2\n",
    "    pix_per_cm = scn_width/screen_info['monitorwidth']\n",
    "    size_pix = size_cm*pix_per_cm\n",
    "    return int(np.round(size_pix))\n",
    "\n",
    "def pix_to_deg(full_size_pix,screen_info,scn_width):\n",
    "    pix_per_cm = scn_width/screen_info['monitorwidth']\n",
    "    size_cm = full_size_pix/pix_per_cm\n",
    "    dva = (size_cm/2/screen_info['viewdist'])*2\n",
    "    return np.rad2deg(dva)\n",
    "\n",
    "def eyetracking_calib(win,el_tracker): \n",
    "    win.flip()\n",
    "    try:\n",
    "        el_tracker.doTrackerSetup()\n",
    "    except RuntimeError as err:\n",
    "        print('ERROR:', err)\n",
    "        el_tracker.exitCalibration()\n",
    "    el_tracker = pylink.getEYELINK()\n",
    "    el_tracker.setOfflineMode()\n",
    "    el_tracker.sendCommand('clear_screen 0')\n",
    "    el_tracker.startRecording(1, 1, 1, 1)\n",
    "    core.wait(1)\n",
    "\n",
    "def eyetracker_exit(el_tracker,fname,results_folder):\n",
    "    el_tracker.stopRecording()\n",
    "    el_tracker.setOfflineMode()\n",
    "    el_tracker.sendCommand('clear_screen 0')\n",
    "    pylink.msecDelay(500)\n",
    "    el_tracker.closeDataFile()\n",
    "    print('EDF data is transferring from EyeLink Host PC...')\n",
    "    el_tracker.receiveDataFile(fname + '.edf', results_folder +'/' + fname +'.edf')\n",
    "    el_tracker.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SET UP SCREEN ENVIRONMENT WITH AND WITHOUT EYETRACKER\n",
    "win=visual.Window(color='Gray',colorSpace='rgb',units='pix',checkTiming=True,fullscr=isfullscreen,winType='pyglet',screen=0)\n",
    "scn_width, scn_height = win.size\n",
    "screen_info = screeninfo(islaptop=islaptop)\n",
    "\n",
    "if iseyetracking:\n",
    "    # Step 1: Connect to the EyeLink Host PC\n",
    "    pylink.closeGraphics()\n",
    "    try:\n",
    "        el_tracker = pylink.EyeLink(\"100.1.1.1\")\n",
    "    except RuntimeError as error:\n",
    "        print('ERROR:', error)\n",
    "        core.quit()\n",
    "\n",
    "    # Step 2: Open an EDF data file on the Host PC\n",
    "    try:\n",
    "        el_tracker.openDataFile(fname)\n",
    "    except RuntimeError as err:\n",
    "        print('ERROR:', err)\n",
    "        if el_tracker.isConnected():\n",
    "            el_tracker.close()\n",
    "        core.quit()\n",
    "\n",
    "    # Step 3: Configure the tracker\n",
    "    el_tracker.setOfflineMode()\n",
    "    vstr = el_tracker.getTrackerVersionString()\n",
    "    eyelink_ver = int(vstr.split()[-1].split('.')[0])\n",
    "    print('Running experiment on %s, version %d' % (vstr, eyelink_ver))\n",
    "    file_event_flags = 'LEFT,RIGHT,FIXATION,SACCADE,BLINK,MESSAGE,BUTTON,INPUT'\n",
    "    link_event_flags = 'LEFT,RIGHT,FIXATION,SACCADE,BLINK,BUTTON,FIXUPDATE,INPUT'\n",
    "    if eyelink_ver > 3:\n",
    "        file_sample_flags = 'LEFT,RIGHT,GAZE,HREF,RAW,AREA,HTARGET,GAZERES,BUTTON,STATUS,INPUT'\n",
    "        link_sample_flags = 'LEFT,RIGHT,GAZE,GAZERES,AREA,HTARGET,STATUS,INPUT'\n",
    "    else:\n",
    "        file_sample_flags = 'LEFT,RIGHT,GAZE,HREF,RAW,AREA,GAZERES,BUTTON,STATUS,INPUT'\n",
    "        link_sample_flags = 'LEFT,RIGHT,GAZE,GAZERES,AREA,STATUS,INPUT'\n",
    "    el_tracker.sendCommand(\"file_event_filter = %s\" % file_event_flags)\n",
    "    el_tracker.sendCommand(\"file_sample_data = %s\" % file_sample_flags)\n",
    "    el_tracker.sendCommand(\"link_event_filter = %s\" % link_event_flags)\n",
    "    el_tracker.sendCommand(\"link_sample_data = %s\" % link_sample_flags)\n",
    "\n",
    "    # Choose a calibration type, H3, HV3, HV5, HV13 (HV = horizontal/vertical),\n",
    "    el_tracker.sendCommand(\"calibration_type = HV5\")\n",
    "   \n",
    "    # Step 4: set up a graphics environment for calibration\n",
    "    el_coords = \"screen_pixel_coords = 0 0 %d %d\" % (scn_width - 1, scn_height - 1)\n",
    "    el_tracker.sendCommand(el_coords)\n",
    "    dv_coords = \"DISPLAY_COORDS  0 0 %d %d\" % (scn_width - 1, scn_height - 1)\n",
    "    el_tracker.sendMessage(dv_coords)\n",
    "    genv = EyeLinkCoreGraphicsPsychoPy(el_tracker, win)\n",
    "    genv.setCalibrationColors((-1, -1, -1), win.color)\n",
    "\n",
    "    # Use a picture as the calibration target (circle is default)\n",
    "    genv.setTargetType('spiral')\n",
    "    \n",
    "    pylink.openGraphicsEx(genv)\n",
    "    try:\n",
    "        el_tracker.doTrackerSetup()\n",
    "    except RuntimeError as err:\n",
    "        print('ERROR:', err)\n",
    "        el_tracker.exitCalibration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "n_blocks = 4\n",
    "total_time = 2.5 # time it would take to move all the way from start to finish\n",
    "n_frames = total_time/(1/refreshrate)+1\n",
    "assert n_frames - int(n_frames) == 0, 'total time has to be divisible by refresh rate'\n",
    "fix_time = 1\n",
    "fix_frames = int(fix_time/(1/refreshrate))\n",
    "response_keys = ['1','0','q','s']\n",
    "\n",
    "# sizes\n",
    "fix_size = deg_to_pix(0.5,screen_info,scn_width)\n",
    "box_pos = deg_to_pix(5,screen_info,scn_width)\n",
    "box_pos=[-box_pos,-box_pos,box_pos,box_pos]\n",
    "\n",
    "dist_start_end = deg_to_pix(13,screen_info,scn_width)\n",
    "dist_start_end = dist_start_end - (dist_start_end % ((n_frames-1)/2)) # find a value that actually fits the total number of frames\n",
    "start_pos = -dist_start_end\n",
    "end_pos = dist_start_end\n",
    "position_vector = np.linspace(start_pos,end_pos,int(n_frames))\n",
    "\n",
    "distance_travelled_pix = end_pos-start_pos\n",
    "distance_travelled_deg = pix_to_deg(distance_travelled_pix,screen_info,scn_width)\n",
    "speed_per_sec=distance_travelled_deg/total_time\n",
    "\n",
    "occluder_width_deg = 9\n",
    "stim_size_deg=0.5\n",
    "stim_size = deg_to_pix(stim_size_deg,screen_info,scn_width)\n",
    "occluder_width = deg_to_pix(occluder_width_deg,screen_info,scn_width)\n",
    "\n",
    "# calculate stop positions -- this is not relevant for this experiment but we need to do it so it's consistent with the speed task\n",
    "n_stops = 7\n",
    "min_max_stop_pos = (occluder_width/2)-(stim_size*2)\n",
    "\n",
    "tmp = np.abs(position_vector - min_max_stop_pos)\n",
    "max_stop_pos = np.max(np.where(np.min(tmp)==tmp))\n",
    "tmp = np.abs(position_vector - -min_max_stop_pos)\n",
    "min_stop_pos = np.min(np.where(np.min(tmp)==tmp))\n",
    "\n",
    "stop_pos = np.round(np.linspace(min_stop_pos,max_stop_pos,n_stops))\n",
    "all_stop_pos=[position_vector[int(i)] for i in stop_pos]\n",
    "all_stop_pos\n",
    "\n",
    "# reappearnace \n",
    "reappearance_loc = (occluder_width/2)-(stim_size/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new speeds, make sure that the stop positions are the same across \n",
    "from functools import reduce\n",
    "def factors(n):    \n",
    "    return (reduce(list.__add__, \n",
    "                ([i, n//i] for i in range(1, int(n**0.5) + 1) if n % i == 0)))\n",
    "\n",
    "movement_resolution = np.unique(np.diff(position_vector))[0] # how many pixels between each position\n",
    "num_frames_stop_pos = np.where(all_stop_pos[1]==position_vector)[0][0]-np.where(all_stop_pos[0]==position_vector)[0][0] # how many refreshs between stop positions\n",
    "pix_between_stop_pos = movement_resolution*num_frames_stop_pos # how many pixels between stop positions\n",
    "\n",
    "# we can only scale the speed in a certain way given that we want to make sure the stop positions stay consistent        \n",
    "possible_factors=np.sort(factors(pix_between_stop_pos))\n",
    "factors_slow = possible_factors[possible_factors>np.max([movement_resolution,num_frames_stop_pos])]\n",
    "factors_fast = possible_factors[possible_factors<np.min([movement_resolution,num_frames_stop_pos])]\n",
    "\n",
    "# adding 4 speeds in total, so we'll end with 5 (with the inital one being in the middle)\n",
    "# pix_per_refresh = np.flip(np.sort(np.hstack((factors_slow[0:2],movement_resolution,factors_fast[-2:]))))\n",
    "pix_per_refresh = np.flip(np.sort(np.hstack((factors_slow[0:1],movement_resolution,factors_fast[-1:]))))\n",
    "\n",
    "pix_per_refresh = np.flip(np.arange(pix_per_refresh[-1],pix_per_refresh[0]))\n",
    "\n",
    "\n",
    "all_pos = []\n",
    "for i in pix_per_refresh:\n",
    "    tmp = np.arange(0,end_pos+i,i)\n",
    "    new_end_pos = tmp[np.argmin(end_pos-tmp)]\n",
    "    all_pos.append(np.arange(new_end_pos*-1,new_end_pos+1,i))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Index([&#39;participant&#39;, &#39;block&#39;, &#39;trial&#39;, &#39;direction&#39;, &#39;start_pos&#39;,\n       &#39;start_pos_deg&#39;, &#39;t_start&#39;, &#39;t_end&#39;, &#39;speed_idx&#39;, &#39;total_time&#39;,\n       &#39;trial_time&#39;, &#39;reappearance_time&#39;, &#39;reappearance_loc&#39;,\n       &#39;reappearance_loc_deg&#39;, &#39;pix_per_refresh&#39;, &#39;deg_per_sec&#39;, &#39;pix_per_sec&#39;,\n       &#39;pos_pressed&#39;, &#39;pos_pressed_deg&#39;, &#39;error&#39;, &#39;error_deg&#39;, &#39;rt&#39;,\n       &#39;widthpix&#39;, &#39;heightpix&#39;, &#39;viewdist&#39;, &#39;monitorwidth&#39;],\n      dtype=&#39;object&#39;)"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# TRIALMATRIX\n",
    "# So these speeds need to be defined in a way that we know for *certain* that the stop positions are in it \n",
    "n_directions = 2\n",
    "n_unique_trials = 1\n",
    "trl_cols = ['participant','block','trial','direction','start_pos','start_pos_deg','t_start','t_end','speed_idx','total_time','trial_time','reappearance_time','reappearance_loc','reappearance_loc_deg','pix_per_refresh','deg_per_sec','pix_per_sec','pos_pressed','pos_pressed_deg','error','error_deg','rt']\n",
    "trialmat = pd.DataFrame(np.zeros((int(n_unique_trials),len(trl_cols))),columns=trl_cols)\n",
    "trialmat['participant'] = fname\n",
    "trialmat['block'] = 1\n",
    "trialmat['trial'] = range(1,int(n_unique_trials)+1)\n",
    "trialmat['direction']=1\n",
    "trialmat['reappearance_loc'] = reappearance_loc\n",
    "trialmat['reappearance_loc_deg'] = pix_to_deg(reappearance_loc,screen_info,scn_width)\n",
    "trialmat['widthpix']=scn_width\n",
    "trialmat['heightpix']=scn_height\n",
    "trialmat['viewdist']=screen_info['viewdist']\n",
    "trialmat['monitorwidth']=screen_info['monitorwidth']\n",
    "\n",
    "\n",
    "# copy for different speeds\n",
    "trialmats_tmp = []\n",
    "for i in range(len(pix_per_refresh)):\n",
    "    trialmats_a = trialmat.copy()\n",
    "    trialmats_a.pix_per_refresh = pix_per_refresh[i]\n",
    "    \n",
    "    trialmats_a.start_pos = all_pos[i][0]\n",
    "    trialmats_a.start_pos_deg = pix_to_deg(all_pos[i][0],screen_info,scn_width)\n",
    "\n",
    "    trialmats_a.trial_time = np.abs(((trialmats_a.reappearance_loc-trialmats_a.start_pos)/trialmats_a.pix_per_refresh)*(1/refreshrate))\n",
    "    trialmats_a.total_time = ((np.abs(trialmats_a.start_pos)*2)/trialmats_a.pix_per_refresh)*(1/refreshrate)\n",
    "   \n",
    "    trialmats_a.speed_idx = i\n",
    "    distance_travelled_pix = all_pos[i][-1]-all_pos[i][0]\n",
    "    distance_travelled_deg = pix_to_deg(distance_travelled_pix,screen_info,scn_width)\n",
    "    trialmats_a.deg_per_sec=distance_travelled_deg/trialmats_a.total_time\n",
    "    trialmats_a.pix_per_sec=distance_travelled_pix/trialmats_a.total_time\n",
    "\n",
    "    # calculate when and where the object would re-appear if it just continued moving\n",
    "    trialmats_a.reappearance_loc = reappearance_loc\n",
    "    time_per_pixel = 1/trialmats_a.pix_per_sec\n",
    "    trialmats_a.reappearance_time = np.abs(time_per_pixel*(trialmats_a.reappearance_loc-trialmats_a.start_pos))\n",
    "\n",
    "    trialmats_tmp.append(trialmats_a)\n",
    "trialmats = pd.concat(trialmats_tmp)\n",
    "\n",
    "\n",
    "# reverse for different directions\n",
    "trialmat_r = trialmats.copy()\n",
    "trialmat_r['start_pos'] = trialmat_r['start_pos']*-1\n",
    "trialmat_r['start_pos_deg'] = trialmat_r['start_pos_deg']*-1\n",
    "trialmat_r['direction']=2\n",
    "trialmat_r.reappearance_loc = -reappearance_loc\n",
    "time_per_pixel = 1/trialmat_r.pix_per_sec\n",
    "trialmat_r.reappearance_time = np.abs(time_per_pixel*(trialmat_r.reappearance_loc-trialmat_r.start_pos))\n",
    "trialmat_r.trial_time = np.abs(((trialmat_r.reappearance_loc-trialmat_r.start_pos)/trialmat_r.pix_per_refresh)*(1/refreshrate))\n",
    "\n",
    "trialmats = pd.concat([trialmats,trialmat_r],ignore_index=True)\n",
    "\n",
    "\n",
    "# randomize and stack some trialmats to generate multiple blocks\n",
    "trialmats=trialmats.sample(frac=1)\n",
    "trialmats.reset_index(drop=True,inplace=True)\n",
    "for b in range(n_blocks):\n",
    "    tmp=trialmats.sample(frac=1)\n",
    "    tmp.reset_index(drop=True,inplace=True)\n",
    "    tmp['block'] = b+1\n",
    "\n",
    "    if b ==0:\n",
    "        trial_df = tmp\n",
    "    else: \n",
    "        trial_df = pd.concat([trial_df,tmp],ignore_index=True)\n",
    "    \n",
    "\n",
    "trial_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visual objects\n",
    "occluder = visual.Rect(win=win, width=occluder_width, height=int(occluder_width/4), units='pix', lineWidth=2, lineColor=None,fillColor='DimGrey', pos=[0,0],opacity=1)\n",
    "fixation = []\n",
    "fixation.append(visual.Circle(win=win,size = fix_size,fillColor='grey',units='pix',lineWidth=0))\n",
    "fixation.append(visual.Rect(win=win,width = fix_size/8,height=fix_size,fillColor='grey',lineWidth=0))\n",
    "fixation.append(visual.Rect(win=win,height = fix_size/8,width=fix_size,fillColor='grey',lineWidth=0))\n",
    "stim = visual.circle.Circle(win, size = stim_size, units='pix', lineWidth=0, fillColor='orange', pos=(0, 0))\n",
    "marker = visual.Polygon(win=win,fillColor='black',size = fix_size,edges=3)\n",
    "\n",
    "# sound object\n",
    "mysound = sound.Sound('C',secs=20, hamming=False, syncToWin=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "5.7589 \tWARNING \tMonitor specification not found. Creating a temporary one...\n5.7610 \tWARNING \tUser requested fullscreen with size [800 600], but screen is actually [1920, 1080]. Using actual size\n"
    }
   ],
   "source": [
    "calib_next_trial,block_end = 1,1\n",
    "for t in range(len(trial_df)):\n",
    "    if calib_next_trial:\n",
    "        pressed=[]\n",
    "        while 1:  \n",
    "            if block_end==1:\n",
    "                text=visual.TextStim(win,text='Block ' + str(trial_df.loc[t,'block']) + ' out of ' +str(n_blocks) +'\\n\\n Press SPACE to start.',height=40)\n",
    "            else:\n",
    "                text = visual.TextStim(win,text='Take a short break!\\n\\n Press SPACE to continue.',height=40)\n",
    "            text.draw()\n",
    "            win.flip()\n",
    "            pressed=event.getKeys(keyList='space', modifiers=False, timeStamped=False) \n",
    "            if pressed:\n",
    "                break\n",
    "        # eyetracking calibration\n",
    "        if iseyetracking: \n",
    "            text=visual.TextStim(win,text='Eye-tracker (re-)calibration...',height=30)\n",
    "            text.draw()\n",
    "            win.flip()\n",
    "            core.wait(2)\n",
    "            eyetracking_calib(win,el_tracker)\n",
    "\n",
    "    win.mouseVisible = False\n",
    "    # draw fixation\n",
    "    for f in range(fix_frames):\n",
    "        for i in fixation:  \n",
    "            i.draw()\n",
    "        win.flip()\n",
    "\n",
    "    # draw stimuli and play sound\n",
    "    if iseyetracking:\n",
    "        el_tracker.sendMessage('TRIAL %d stim_on' % t)\n",
    "        el_tracker.sendCommand(\"record_status_message '%s'\" % 'TRIAL number %d stim_on' % t)\n",
    "\n",
    "    next_flip = win.getFutureFlipTime(clock='ptb')\n",
    "    mysound.play(when=next_flip)\n",
    "    if trial_df.loc[t,'direction']==1:\n",
    "        pos_vec = all_pos[trial_df.loc[t,'speed_idx']]\n",
    "        pos_vec = pos_vec[pos_vec<reappearance_loc]\n",
    "    else:\n",
    "        pos_vec = np.flip(all_pos[trial_df.loc[t,'speed_idx']])\n",
    "        pos_vec = pos_vec[pos_vec>-reappearance_loc]\n",
    "\n",
    "    # wait for response and end trial when participant has pressed the button\n",
    "    resp = ()\n",
    "    for i,j in enumerate(pos_vec):\n",
    "        stim.pos = (j,0)\n",
    "        stim.draw()\n",
    "        occluder.draw()\n",
    "        if i == 0:\n",
    "            trial_df.loc[t,'t_start'] = win.flip()\n",
    "        else:\n",
    "            trial_df.loc[t,'t_end']=win.flip()\n",
    "        resp=event.getKeys(keyList='space', modifiers=False, timeStamped=True)\n",
    "        if any(resp):\n",
    "            mysound.stop()\n",
    "            if iseyetracking:\n",
    "                el_tracker.sendMessage('TRIAL %d stim_off' % t)\n",
    "                el_tracker.sendCommand(\"record_status_message '%s'\" % 'TRIAL number %d stim_off' % t)\n",
    "            break\n",
    "\n",
    "    # wait for the participant to press button or until 2 s have passed\n",
    "    if not any(resp):\n",
    "        t1 = time.time()\n",
    "        while 1:\n",
    "            stim.draw()\n",
    "            occluder.draw()\n",
    "            trial_df.loc[t,'t_end']=win.flip()\n",
    "            resp=event.getKeys(keyList='space', modifiers=False, timeStamped=True)\n",
    "            if any(resp) or (time.time()-t1)>2:\n",
    "                mysound.stop()\n",
    "                break\n",
    "\n",
    "    if any(resp):\n",
    "        trial_df.loc[t,'rt'] = resp[0][1]-trial_df.loc[t,'t_start']\n",
    "        if trial_df.loc[t,'direction']==1:\n",
    "            trial_df.loc[t,'pos_pressed']=trial_df.loc[t,'start_pos']+trial_df.loc[t,'rt']*trial_df.loc[t,'pix_per_sec']\n",
    "            trial_df.loc[t,'error']=(trial_df.loc[t,'reappearance_loc']-trial_df.loc[t,'pos_pressed'])\n",
    "        else:\n",
    "            trial_df.loc[t,'pos_pressed']=trial_df.loc[t,'start_pos']-trial_df.loc[t,'rt']*trial_df.loc[t,'pix_per_sec']\n",
    "            trial_df.loc[t,'error']=(trial_df.loc[t,'reappearance_loc']-trial_df.loc[t,'pos_pressed'])*-1\n",
    "        trial_df.loc[t,'error_sec']=trial_df.loc[t,'rt']-trial_df.loc[t,'reappearance_time']\n",
    "        trial_df.loc[t,'error_deg'] = pix_to_deg(trial_df.loc[t,'error'],screen_info,scn_width) \n",
    "        trial_df.loc[t,'pos_pressed_deg'] = pix_to_deg(trial_df.loc[t,'pos_pressed'],screen_info,scn_width) \n",
    "\n",
    "    # add 1 sec blank screen\n",
    "    win.flip()\n",
    "    core.wait(1)\n",
    "\n",
    "    # show a bit of text before next trial\n",
    "    txt = visual.TextStim(win,text='Get ready...',pos=(0,0),height=30)\n",
    "    t1 = time.time()\n",
    "    while 1:\n",
    "        txt.draw()\n",
    "        win.flip()\n",
    "        pressedq=event.getKeys(keyList=['q'], modifiers=False, timeStamped=False) \n",
    "        if pressedq:\n",
    "            win.close()\n",
    "        if (time.time()-t1)>1:\n",
    "            break\n",
    "\n",
    "    if np.any(np.isin(np.where(np.diff(trial_df['block']))[0],t)):\n",
    "        calib_next_trial = 1\n",
    "        block_end = 1\n",
    "    else: \n",
    "        calib_next_trial = 0\n",
    "        block_end = 0\n",
    "\n",
    "\n",
    "# End of the experiment -- save data and close eyetracker\n",
    "txt=visual.TextStim(win=win,text='End of experiment :)',height = 30)\n",
    "txt.draw()\n",
    "win.flip()\n",
    "core.wait(5)\n",
    "win.close()\n",
    "trial_df.to_csv('./' + results_folder +'/' + fname + '_trialmat.csv')\n",
    "\n",
    "if iseyetracking:\n",
    "    try:\n",
    "        eyetracker_exit(el_tracker,fname,results_folder)\n",
    "    except RuntimeError as error:\n",
    "        print('that did not work...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "38a77d295606b995ef971b4c58125e8c41f77cd8c0384c8daba3d9c73f5fdc28"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11-final"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}